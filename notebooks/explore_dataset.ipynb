{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 5min 数据集探索\n",
    "- 分布 / 缺失 / 对齐检查\n",
    "- 请先生成 `workshop_5min_clean_all.csv` 再运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "DATA_PATH = Path(\"../workshop_5min_clean_all.csv\")\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"CSV not found: {DATA_PATH}\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"ts_5min\"])\n",
    "df = df.sort_values(\"ts_5min\").reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本信息\n",
    "print(\"shape:\", df.shape)\n",
    "display(df.dtypes)\n",
    "print(\"ts_5min min/max:\", df[\"ts_5min\"].min(), df[\"ts_5min\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值统计\n",
    "na_counts = df.isna().sum()\n",
    "na_pct = (na_counts / len(df) * 100).round(2)\n",
    "na_report = pd.DataFrame({\"na_count\": na_counts, \"na_pct\": na_pct}).sort_values(\"na_pct\", ascending=False)\n",
    "display(na_report)\n",
    "\n",
    "# 可视化缺失比例（前 30 列）\n",
    "top_cols = na_report.head(30).index\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.barplot(x=na_report.loc[top_cols, \"na_pct\"], y=top_cols, orient=\"h\")\n",
    "plt.title(\"Missing percentage (top 30)\")\n",
    "plt.xlabel(\"% of missing\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间对齐检查：重复 / 缺口 / 每天行数\n",
    "t = df[\"ts_5min\"]\n",
    "dup_count = t.duplicated().sum()\n",
    "print(\"Duplicated ts_5min:\", dup_count)\n",
    "\n",
    "# 期望频率 5min，找缺口\n",
    "full = pd.date_range(start=t.min(), end=t.max(), freq=\"5min\")\n",
    "missing_ts = full.difference(t)\n",
    "print(\"Missing timestamps count:\", len(missing_ts))\n",
    "if len(missing_ts) > 0:\n",
    "    display(pd.Series(missing_ts[:20], name=\"missing_ts_sample\"))\n",
    "\n",
    "# 每天记录数，完整日应为 288 条\n",
    "df[\"date\"] = df[\"ts_5min\"].dt.date\n",
    "day_counts = df.groupby(\"date\").size().rename(\"rows_per_day\")\n",
    "display(day_counts.describe())\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.barplot(x=day_counts.index.astype(str), y=day_counts.values, color=\"steelblue\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.axhline(288, color=\"red\", linestyle=\"--\", label=\"expected 288\")\n",
    "plt.legend()\n",
    "plt.title(\"Rows per day\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 清理临时列\n",
    "df.drop(columns=[\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数值列分布（排除时间特征）\n",
    "num_cols = [c for c in df.columns if c != \"ts_5min\" and pd.api.types.is_numeric_dtype(df[c])]\n",
    "focus_cols = [c for c in num_cols if c not in (\"dayofweek\", \"is_weekend\")]\n",
    "\n",
    "display(df[focus_cols].describe())\n",
    "\n",
    "n_show = min(6, len(focus_cols))\n",
    "plt.figure(figsize=(14, 8))\n",
    "for i, col in enumerate(focus_cols[:n_show], 1):\n",
    "    plt.subplot(2, (n_show + 1) // 2, i)\n",
    "    sns.histplot(df[col].dropna(), bins=50, kde=True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相关性热力图（数值列）\n",
    "if len(focus_cols) > 1:\n",
    "    corr = df[focus_cols].corr()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr, cmap=\"coolwarm\", center=0, annot=False)\n",
    "    plt.title(\"Correlation (numeric features)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "489485d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: D:\\Python_Graduate_Project\\workshop4_energy_prediction\n"
     ]
    }
   ],
   "source": [
    "# ==== 1. 把项目根目录加入 sys.path，方便 import 自己的包 ====\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# 假设当前 notebook 在 project_root/notebooks/ 目录下\n",
    "ROOT_DIR = Path(\"..\").resolve()\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.append(str(ROOT_DIR))\n",
    "\n",
    "print(\"Project root:\", ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ae208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ts_5min', 'bf_power', 'cold_power', 'cold_freq', 'exh_power', 'exh_freq', 'exh_voltage_v', 'exh_moto_temp', 'exh_ambient_temp', 'env_temp', 'env_hum', 'env_press', 'main_power', 'dayofweek', 'is_weekend', 'tod_sin', 'tod_cos']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from config.dataset_config import TRAIN_CSV\n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09035c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODE_LOCAL_FEATURES = {'BF': ['bf_power'], 'Cold': ['cold_power', 'cold_freq'], 'Exhaust': ['exh_voltage_v', 'exh_moto_temp'], 'Env': ['env_temp', 'env_hum', 'env_press'], 'Main': ['main_power']}\n",
      "TIME_FEATURES       = ['dayofweek', 'is_weekend', 'tod_sin', 'tod_cos']\n",
      "model_config.py from: D:\\Python_Graduate_Project\\workshop4_energy_prediction\\config\\model_config.py\n"
     ]
    }
   ],
   "source": [
    "import config.model_config as mc\n",
    "from importlib import reload\n",
    "\n",
    "# 保险起见先强制 reload 一次\n",
    "mc = reload(mc)\n",
    "\n",
    "print(\"NODE_LOCAL_FEATURES =\", mc.NODE_LOCAL_FEATURES)\n",
    "print(\"TIME_FEATURES       =\", mc.TIME_FEATURES)\n",
    "print(\"model_config.py from:\", mc.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd04fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CSV: D:\\Python_Graduate_Project\\workshop4_energy_prediction\\workshop_5min_train.csv\n",
      "Val   CSV: D:\\Python_Graduate_Project\\workshop4_energy_prediction\\workshop_5min_val.csv\n",
      "Scaler mean keys: ['bf_power', 'cold_freq', 'cold_power', 'env_hum', 'env_press', 'env_temp', 'exh_moto_temp', 'exh_voltage_v', 'main_power', 'dayofweek']\n",
      "Train samples: 3457\n",
      "Val   samples: 289\n",
      "X shape: torch.Size([16, 288, 5, 7])\n",
      "y shape: torch.Size([16, 288])\n",
      "Sample[0] node0 first 3 steps:\n",
      " tensor([[ 0.5947,  0.5000, -0.6325, -0.6530, -1.2544,  0.0000,  0.0000],\n",
      "        [ 0.5940,  0.5000, -0.6325, -0.6802, -1.2399,  0.0000,  0.0000],\n",
      "        [ 0.5700,  0.5000, -0.6325, -0.7071, -1.2247,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = Path(\"..\").resolve()\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.append(str(ROOT_DIR))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config.dataset_config import TRAIN_CSV, VAL_CSV\n",
    "from data.graph_dataset import GraphSequenceDataset, fit_scaler_from_csv\n",
    "\n",
    "print(\"Train CSV:\", TRAIN_CSV)\n",
    "print(\"Val   CSV:\", VAL_CSV)\n",
    "\n",
    "scaler = fit_scaler_from_csv(str(TRAIN_CSV))\n",
    "print(\"Scaler mean keys:\", list(scaler[\"mean\"].index)[:10])\n",
    "\n",
    "train_ds = GraphSequenceDataset(\n",
    "    csv_path=str(TRAIN_CSV),\n",
    "    t_in=288,\n",
    "    t_out=288,\n",
    "    feature_scaler=scaler,\n",
    "    fit_scaler=False,\n",
    ")\n",
    "\n",
    "val_ds = GraphSequenceDataset(\n",
    "    csv_path=str(VAL_CSV),\n",
    "    t_in=288,\n",
    "    t_out=288,\n",
    "    feature_scaler=scaler,\n",
    "    fit_scaler=False,\n",
    ")\n",
    "\n",
    "print(\"Train samples:\", len(train_ds))\n",
    "print(\"Val   samples:\", len(val_ds))\n",
    "\n",
    "loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "X, y = next(iter(loader))\n",
    "print(\"X shape:\", X.shape)  # 预期 (16, 288, 5, F_max)\n",
    "print(\"y shape:\", y.shape)  # 预期 (16, 288)\n",
    "\n",
    "print(\"Sample[0] node0 first 3 steps:\\n\", X[0, :3, 0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d5699d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
